% !TEX root = ../../main.tex

\begin{table*}[bp]
    \centering
    \footnotesize
    % \tiny
    \begin{subtable}[t!]{\textwidth}
    \rowcolors{2}{white}{gray!25} % \rowcolors{<starting row index>}{<dispari row color>}{<pari row color>}
    \centering
        \begin{tabular}{l | c  r  c  c}
        % \toprule
        Clustering problem & \makecell{Graph Type} & $\#I$ & $|V|$ & $|E|$ \\ \midrule
        \emph{Modularity Clustering} \cite{brandes2007modularity} & \emph{complete} & 6& 34-115 & 561-6555 \\ 
        \emph{Image Segmentation} \cite{andres2011probabilistic} & \emph{RAG} & 100 & 156-3764 &  439-10970 \\
        \emph{Knott-3D (150-300-450)} \cite{andres2012globally} & \emph{3D-RAG} & 24 & 572-17k & 3381-107k \\
        \emph{CREMI-3D-RAG (OurCNN)}  & \emph{3D-RAG} & 3& 134k-157k & 928k-1065k \\ 
        \emph{Fruit-Fly Level 1-4} \cite{pape2017solving} & \emph{3D-RAG} & 4& 5m-11m & 28m-72m \\
        \emph{CREMI-gridGraph (OurCNN)} & \emph{gridGraph} & 15& 39m & 140m \\
        \emph{Fruit-Fly Level Global} \cite{pape2017solving} & \emph{3D-RAG} & 1& 90m & 650m \\
        \end{tabular}
    \end{subtable} 
    \caption{List of compared signed graph clustering problems: for each, we specify the number of instances $\# I$, number of nodes $|V|$, and number of edges $|E|$ per instance.} 
    \label{tab:datasets}
\end{table*}




\section{Experiments}\label{sec:neuro_segm_exp}
\subsection{Signed graph clustering problems} \label{sec:clustering_problems}
We evaluate the agglomerative clustering algorithms included in our framework on a large collection of both synthetic and real-world graphs with very different structures. The size of the graphs ranges from a few hundred to hundreds of millions of edges.

\paragraph{Synthetic SSBM graphs} We first consider synthetic graphs generated by a signed stochastic block model (SSBM). We use an Erd\H os-R\'enyi random graph model $\mathcal{G}(N,p)$ with $N$ vertices and edge probability $p$. Following the approach in \cite{Cucuringu2019SPONGEAG}, we partitioned the graph into $k$ \emph{ground-truth} clusters, such that edges connecting vertices belonging to the same cluster (different clusters, respectively) have Gaussian distributed edge weights centered at $\mu=1$ ($\mu=-1$, respectively) and with standard deviation $\sigma=0.1$. To model noise, the sign of the edge weights is flipped independently with probability $\eta$.


\paragraph{Existing signed graphs}   We use clustering instances from the OpenGM benchmark \cite{kappes2013comparative} as well as biomedical segmentation instances \cite{pape2017solving}. The dataset \emph{Image Segmentation} contains planar region-adjacency-graphs (RAG) that are constructed from superpixel adjacencies of photographs. The \emph{Knott-3D} datasets contains 3D-RAGs arising from volume images acquired by electron microscopy (EM). The set \emph{Modularity Clustering} contains complete graphs constructed from clustering problems on small social networks. The \emph{Fruit-Fly} 3D-RAG instances were generated from volume image scans of fruit fly brain matter. Instances \emph{Level 1-4} are progressively simplified versions of the global problem obtained via block-wise domain decomposition \cite{pape2017solving}.

\paragraph{Grid-graphs from CNN predictions}  We also evaluate the clustering methods on the task of neuron segmentation in EM image volumes using training data from the CREMI 2016 EM Segmentation Challenge \cite{cremi}.
We train a 3D U-Net \cite{ronneberger2015u,cciccek20163d} using the same architecture as \cite{funke2018large} and predict long-and-short range affinities 
as described in \cite{lee2017superhuman}. The predicted affinities $a_e\in[0,1]$, which represent how likely it is for a pair of pixels to belong to the same neuron segment, are then mapped to signed edge weights $w_e=a_e-0.5$, resulting in a 3D grid-graph having a node for each pixel/voxel of the  image\footnote{To map affinities to signed weights, we also tested the \emph{logarithmic mapping} proposed in \cite{finkel2008enforcing,andres2012globally}, but it performed worse in our experiments.}. 
% \TODO{long-range 10\%} 
% Adding long-range connections to the graph is generally helpful, but when many of them carry repulsive weights. Long-range connections are more noisy. 10\% represents a good compromise.
We divided the three CREMI training samples, consisting of $\sim$196 million voxels each, into five sub-blocks for a total of 15 clustering problems (named \emph{CREMI-gridGraph} in Table~\ref{tab:datasets}). See the following Section \ref{sec:cremi_details} for extended details about training, data augmentation, and how we remove tiny clusters left after running \algname{} on the \emph{CREMI-gridGraph} clustering problems.

\paragraph{3D-RAG from CNN-predictions} Lastly, we use the predictions of our CNN model to generate three graph instances (one for each CREMI training sample, named \emph{CREMI-3D-RAG} in Table~\ref{tab:datasets}), which have very similar structure to the \emph{Knott-3D} and \emph{Fruit-Fly} instances.  We obtain these problems by using a pipeline that is very common in neuron segmentation: a watershed algorithm generates superpixels and from those a 3D region-adjacency graph is built, where edge weights are given by the CNN predictions averaged over the boundaries of adjacent superpixels (details in the following Section \ref{sec:cremi_details}). 
% them by first computing 2D supervoxels from the CNN predictions (using a watershed algorithm seeded at the maxima of the smoothed boundary distance transform) and then building a 3D region-adjacency graph, whose edge weights are given by the CNN affinities averaged over the boundaries of adjacent supervoxels.

% This is true for the neuron instances generated from the CREMI challenge, where training data is available, and for synthetic graphs generated with SSBM.   


% Fig.~\ref{fig:noise_plots} summarizes our 12000 noise experiments: we focus on the best performing linkage criteria, i.e. \emph{Average}, \emph{Sum} and \emph{Abs Max}, and test them with different amount of noise. 
% In these experiments, we also want to assess how beneficial it is to use long-range CNN predictions in the agglomeration. Thus, we perform a set of simulations without adding long-range connections to the grid-graph and another set where we introduce them with a 10\% probability\footnote{We also performed experiments adding all the long-range predictions given by the CNN model, but we did not note major differences when using only 10\% of them. Adding this fraction is usually sufficient to improve the scores.}.\\



% , where $\beta \in [0,1]$ is a \emph{bias} parameter that allow a tuning between over- and under-segmentation and in our case was set to $\beta=0.5$.
% Neuron segmentation is commonly performed by first predicting undirected affinities \cite{wolf2018mutex,lee2017superhuman,funke2018large}, which represent how likely it is for a pair of pixels to belong to the same neuron segment. 
% Similarly to \cite{lee2017superhuman}, we train a UNet model CITE to predict both short- and long-range affinities that are not limited to adjacent pixels. These predictions are then used as edge weights of a 3D grid graph, where each node represents a pixel/voxel of the volume image. 
 


% ---
% We first evaluate and compare the agglomerative clustering algorithms described in the generalized framework on the task of neuron segmentation in electron microscopy (EM) image volumes. This application is of key interest in connectomics, a field of neuro-science with the goal of reconstructing neural wiring diagrams spanning complete central nervous systems. Currently, only proof-reading or manual tracing yields sufficient accuracy for correct circuit reconstruction \cite{schlegel2017learning}, thus further progress is required in automated reconstruction methods.





% ----
% We evaluate all algorithms in the proposed framework on the competitive CREMI 2016 EM Segmentation Challenge \cite{cremiChallenge} that is currently the neuron segmentation challenge with the largest amount of training data available. The dataset comes from serial section EM of \emph{Drosophila} fruit-fly tissue and consists of 6 volumes of 1250x1250x125 voxels at resolution 4x4x40nm, three of which come with publicly available training ground truth. The results submitted to the leaderboard are evaluated using the CREMI score, based on the Adapted Rand-Score (Rand-Score) and the Variation of Information Score \cite{arganda2015crowdsourcing}. In Appendix \ref{sec:cremi_details}, we provide more details about the training of our CNN model, inspired by work of \cite{lee2017superhuman,funke2018large}.


\subsection{Details on neuron segmentation graph instances}\label{sec:cremi_details}
\paragraph{Training and data augmentation} The data from the CREMI challenge is highly \linebreak anisotropic and contains artifacts like missing sections, staining precipitations and support film folds. 
To alleviate difficulties stemming from misalignment, we use a version of the data that was elastically realigned by the challenge organizers with the method of \cite{saalfeld2012elastic}.
% We train a 3D U-Net \cite{ronneberger2015u,cciccek20163d} using the same architecture as \cite{funke2018large} and predict the same set of long-and-short range affinities described in \cite{lee2017superhuman}. 
In addition to the standard data augmentation techniques of random rotations, random flips and  elastic deformations, we simulate data artifacts.
We randomly zero-out slices, decrease the contrast of slices, simulate tears, introduce alignment jitter and paste artifacts extracted from the training data. Both \cite{funke2018large} and \cite{lee2017superhuman} have shown
that these kinds of augmentations can help to alleviate issues caused by EM-imaging artifacts.
We use L2 loss and Adam optimizer to train the network. The model was trained on all three samples with available ground truth labels.  

\paragraph{CREMI-gridRag instances} 
Our 3D UNet model predicts the same set of 12 long-and-short range affinities as described in \cite{lee2017superhuman}. 
When building the pixel-grid graph, we add both direct neighbors connections and the long-range connections predicted by our model (every voxel is connected to other six voxels via direct connections and other 18 voxels via long-range edges).
Empirically, when long-range predictions of the CNN are added as long-range connections in the graph, \algname{} achieves better scores as compared to when only direct-neighbors predictions are used.
% Empirically, we found that adding only 10\% of the long-range connections to the grid-graph (by sampling them at random) gave the best results.
Our intuitive explanation of this is that, where there is a clear boundary evidence between two segments, the long-range predictions of the CNN model are more certain than the direct-neighbor ones, because it is often impossible to estimate the exact ground-truth label transition for pixels that are very close to a boundary evidence. 
However, empirically, we also find that \algname{} achieves the best scores when only 10\% of the long-range connections are randomly sampled and added to the grid-graph. When all the long-range connections predicted by the CNN are added to the graph (18 connections for every voxel), all versions of \algname{} tend to perform more over-clustering errors.
In practice, we explain this by observing that many challenging parts of the studied neuron segmentation data involve thin and elongated segments, and our model sometimes fails to connect distant pairs of pixels that, according to the ground-truth labels, should belong to the same segment (even though, in this case, the direct neighboring predictions are correct).
To sum up, the scores we report in Tables \ref{tab:scores_gridGraph} are obtained by using only 10\% of the long-range predictions, since this was the setup that performed the best.
After running \algname{}, we use a simple post-processing step to delete small segments on the boundaries, most of which are given by single-voxel clusters. On the neuron segmentation predictions, we deleted all regions with less than 200 voxels and used a seeded watershed algorithm to expand the bigger segments.



\paragraph{CREMI-3D-rag instances} 
We build these clustering problems by generating superpixels and then building a 3D region adjacency graph.
Due to the anisotropy of the data, we generate 2D superpixels by considering each 2D image in the stack singularly.
First, we generate a boundary-evidence map by taking an average over the two direct-neighbor predictions of the CNN model (one for each direction in the 2D image of the stack) and applying some additional smoothing. Then, we threshold the boundary map, compute a distance transform, and run a watershed algorithm seeded at the maxima of the distance transform (WSDT). The degree of smoothing was optimized such that each region receives as few seeds as possible, without however causing severe under-segmentation. 
The computed 2D superpixels are then used to build a 3D region-adjacency graph (3D-rag). The weights of the edges are given by averaging the CNN affinities over the boundaries of adjacent superpixels. 








\subsection{Comparison of results and discussion}\label{sec:experiments_discussion}
% Before to evaluate the clustering algorithms on real-world graphs, we compare them on two types of synthetically generated graphs and highlight some of their fundamental properties.

\paragraph{Multicut objective values} In Table~\ref{tab:energies}, we report the values of the multicut objective obtained for clustering with different \algname{} algorithms\footnote{Objective values achieved by Single and Complete linkage methods are much worse compared to other algorithms and are reported in Table \ref{tab:all_multicut_energies}, in Appendix.}. Although many heuristics were proposed to better optimize this objective \cite{beier2016efficient,beier2014cut,kernighan1970efficient}, these methods are out of the scope of this work, since they do not scale to the largest graph instances considered here. By looking at results in Table~\ref{tab:energies}, we observe that GAEC almost always achieves the lowest objective values, expect in the \emph{CREMI-gridGraph} instances. Despite this, on graphs where a ground truth clustering is known, GAEC does not achieve the lowest ARAND errors (see Tables~\ref{tab:scores_gridGraph} and \ref{tab:scores_3drag}). 
% To better understand these empirical results, we now make the following important observation.
% This can also be observed in our experiments on synthetic graphs (Fig. ? and ?), where the clustering with minimum multicut energy become very different from the ground truth clustering when the flip noise parameter $\eta$ is increased.

\paragraph{Size of growing clusters: Sum vs Avg linkage} 
In all the studied clustering problems, we empirically observe that sum-linkage algorithms like GAEC grow clusters one after the other, as shown in Fig.~\hyperref[fig:intro_figure]{\ref*{fig:intro_figure}d} and Fig.~\ref{fig:dendrograms} by the agglomeration order of GAEC\footnote{This \emph{flooding agglomeration-strategy} of GAEC was also observed in \cite{kardoostsolving}.}. This is intuitively explained by the  following: initially, many of the most attractive edge weights have very similar values; when the two nodes $u,v$ with the highest attraction are merged, there is a high chance that they will have a common neighboring node $t$ belonging to the same cluster; thus, the interaction between the merged nodes $uv$ and $t$ is likely assigned to the highest priority, because it is given by the sum of two highly attractive edge weights. This will then start a ``chain reaction'' where only a single cluster is agglomerated at the time. 
% This \emph{flooding strategy} in the agglomeration is not observed with other linkage methods, e.g. Average, which grow clusters of similar sizes in parallel.
In the following, we will show how this unique \emph{flooding strategy} of the sum-linkage methods can be both an advantage or a disadvantage, depending on the type of clustering problem. 

\paragraph{Comparison to spectral clustering} 
The spectral clustering methods for signed graphs SPONGE$_{sym}$ and SPONGE proposed by \cite{Cucuringu2019SPONGEAG} achieved state of the art performances on SSBM synthetic graphs. Their competitive performances are also confirmed by our experiments in Fig.~\ref{fig:SSBM_scores}.
% First, we compare \algname{} to spectral clustering methods for signed graphs. 
% In Fig.~\ref{fig:SSBM_scores}, we see that SPONGE$_{sym}$ and SPONGE proposed by \cite{Cucuringu2019SPONGEAG} perform particularly well on synthetic graphs generated with a SSBM. 
However, these methods do not scale up to the large graph instances considered here and they also require the user to specify the true number of clusters in advance, which is not known for other graph instances tested in this chapter. In Table \ref{tab:cremi_spectral_experiments}, we report the scores achieved by these methods on a much smaller sub-instance of the \emph{CREMI-gridGraph} problem: even when the true number of clusters is specified in advance for the spectral methods, they perform much worse than other \algname{} algorithms, with an accuracy penalty of almost 50\%. For these reasons, we exclude them from our other comparison experiments.  








\begin{figure}[tp]
\begin{subfigure}[t]{0.44\textwidth}
\centering
\includegraphics[width=\textwidth,trim=0.34in 0.34in 0.34in 0.34in,clip]{./figures/GASP/SSBM_scores/summary_SSBM_experiments_k20.pdf}
\caption{$k=20$, $p=0.1$}
\end{subfigure}\hfill
\begin{subfigure}[t]{0.44\textwidth}
\centering
\includegraphics[width=\textwidth,trim=0.34in 0.34in 0.34in 0.34in,clip]{./figures/GASP/SSBM_scores/summary_SSBM_experiments_k50.pdf}
\caption{$k=50$, $p=0.2$}
\end{subfigure}
        \caption{
ARAND errors (median values over 20 experiments, lower is better) on synthetic graphs generated with SSBM. We consider $k$ ground truth communities of random size. Graphs have $N=10000$ nodes and edges are randomly added with probability $p$. 
% The spectral clustering methods, SPONGE and SPONGE$_sym$, were given the true number of clusters as input. 
% Solid lines represent median values over \TODO{30} experiments. Values between the 25th and the 75th percentile are shown in shaded areas.
% We report median, 25th, and the 75th percentile values over \TODO{30} experiments.
%         Scores on SSBM graphs
% \algname{} sensitivity to noise: \emph{Average} linkage proved to be the most robust. Performances are given by Rand-Score (higher is better) depending on the amount of noise added to the CNN predictions.  The two sets of experiments using under- and over-clustering noise are summarized in the plots at the top and at the bottom, respectively (see Appendix \ref{sec:appendix_noise_gen} for more details). For each experiment, some of the long-range CNN predictions were randomly selected with probability $p_{\mathrm{long}}$ and added as long-range edges to the pixel grid-graph. Experiments are performed on a crop of CREMI training sample B.
        } \label{fig:SSBM_scores}
\end{figure}

\begin{table*}[t]
    \centering
    % \scriptsize
    \tiny
    \begin{subtable}[t!]{\textwidth}
    \centering
        \rowcolors{3}{gray!25}{white} % \rowcolors{<starting row index>}{<dispari row color>}{<pari row color>}
        \begin{tabular}{l | r r r r r r r r}
        &\multicolumn{7}{c}{Multicut objective values (average across instances, lower is better)} \\
        Clustering problem & \multicolumn{1}{r}{GAEC \cite{keuper2015efficient}} & HCC-Sum & MWS \cite{wolf2018mutex} & HC-Avg & HCC-Avg & HC-Single & HC-Complete \\ \midrule
        \emph{Modularity Clustering} & 
        -0.457 & -0.453 & -0.073 & \textbf{-0.467} & \textbf{-0.467} & 0.000 & -0.201 \\ 
        \emph{Image Segmentation}  & 
        \textbf{-2,955} & -2,953 & -2,901 & -2,903 & -2,896 & -1,384 &  -2,102 \\
        \emph{Knott-3D (150-300-450)}  & 
        \textbf{-36,667} & -36,652 & -35,200 & -35,957 & -35,631 & -2,522 & 30,629 \\
        \emph{CREMI-3D-rag}  
        & \textbf{-1,112,287} & -1,112,286& -1,109,731 & -1,112,177 & -1,112,100 & -1,038,709 & -748,734,869 \\ 
        \emph{Fruit-Fly Level 1-4}
        & \textbf{-151,022} & -151,017 & -150,879 & -150,909 & -150,876 & -71,477 & -128,733 \\
        \emph{CREMI-gridGraph} 
        & -73,317,601 & -73,328,867 & -73,330,568 & \textbf{-73,502,947} & -73,474,856 & -45,194,180 & 311,598,700 \\
        \emph{Fruit-Fly Level Global} 
        & \textbf{-151,688} & -151,596 & -146,315 & -150,466 & -150,171 & -4,422 & 6,876 \\



        \end{tabular}
    \end{subtable} 
    \caption{We compare algorithms in the \algname{} framework by their value of the multicut objective defined in Eq.~\ref{eq:MC_objective} (lower is better).} 
    \label{tab:energies}
\end{table*}

\begin{figure}[tp]
\centering
% \includegraphics[width=0.48\textwidth,trim=300 100 300 100, clip]{./figures/GASP/dendrograms/new_agglo_order_OLD.png} % left bottom right top
\includegraphics[width=\textwidth,trim=0 10 60 0, clip]{./figures/GASP/dendrograms/new_agglo_order.png} % left bottom right top
\caption{Clustering dynamics and accuracy of GASP variations on stochastic block models. The dendrograms result from three versions of \algname{} on a synthetic graph generated with SSBM ($250$ nodes, edge probability $p=0.05$, flipping probability $\eta=0.1$).  Red and blue colors show which of the two equal-sized ground-truth communities each node belongs to. At the top, dendrograms are truncated at the level of the final clustering $\Pi^*$ returned by \algname{}. \label{fig:dendrograms}}
\end{figure}

\begin{table*}[t]
\centering
% \begin{minipage}[t]{0.48\textwidth}
% \vspace{0pt}
% \centering
\footnotesize
\rowcolors{2}{white}{gray!25} % \rowcolors{<starting row index>}{<dispari row color>}{<pari row color>}
\begin{tabular}[t]{l | c}
\footnotesize
           Method & ARAND Error \\ \midrule
           \textbf{HC-Avg} (GASP with Avg Linkage) & \textbf{0.1034} \\
GAEC \cite{keuper2015efficient} (GASP with Sum Linkage) & 0.1035 \\
MWS \cite{wolf2018mutex} (GASP with AbsMax linkage) & 0.1068 \\
SPONGE$_{sym}$ \cite{Cucuringu2019SPONGEAG} & 0.4161\\
$L_{sym}$ \cite{kunegis2010spectral} & 0.8069 \\
SPONGE \cite{Cucuringu2019SPONGEAG} & 0.9211 \\
BNC \cite{chiang2012scalable} & 0.9926 \\
        \end{tabular}
    \caption{\algname{} compared to spectral clustering methods on a small crop of the CREMI neuron segmentation dataset. 
    Since spectral methods cannot scale to the full CREMI dataset, we evaluated them on a smaller $10\times100\times100$ sub-volume of CREMI training sample B.
    Despite the fact that the true number of ground truth clusters was given as an input to the spectral methods, GASP significantly outperformed them. 
    % SC methods seem to have more difficulties when the graph is sparse. 
    % Spectral methods did not handle well pixels on the boundaries between segments and tended to cluster them together. 
    % We also tried to vary the input number of clusters ncreasing $k$ did not improve their scores either.
% resulting in a graph with $10^5$ nodes and~$\sim10^6$ edges.
    }
    \label{tab:cremi_spectral_experiments}
% \end{minipage}
% \begin{minipage}[t]{0.38\textwidth}
% \vspace{0pt}
% \centering
%         \includegraphics[width=1.\textwidth,trim=0.25in 0.25in 0.68in 0.36in,clip]{./figures/GASP/SSBM_experiments.pdf} % 0.45
%         \caption{\algname{} performances compared to spectral methods on synthetic graphs. The spectral methods were given the true number of clusters as input, in contrast to \algname{}. \TODO{Define paramters SSB; explain percentile stuff (for both noise experiments, save space!)}}
%     \label{fig:SSBM_scores}
% \end{minipage}
\end{table*}


\subsubsection{GASP on synthetic SSBM graphs}   
% can be connected to any  that, depending on the edge-probability parameter $p$, are also \emph{dense}. 
\algname{} algorithms using cannotLinkConstraints are not expected to perform well on these graphs, because of the type of employed sign noise, so we focus our comparison only on the GAEC, HC-Avg and MWS algorithms (using Sum, Average, and AbsMax linkage methods, respectively).
Empirically, we observe that GAEC is the agglomerative algorithm performing best on SSBM graphs, on par with spectral method SPONGE$_{sym}$ (see Fig.~\ref{fig:SSBM_scores}). Given the simple properties of SSBM graphs, we can now give a detailed explanation of these empirical results. 
In SSBM graphs, the number of edges $E_{ij}\equiv(S_i\times S_j)\cap E$ connecting two clusters $S_i,S_j$ is  proportional to the product $|S_i|\cdot|S_j|$ of cluster sizes. 
With Sum or Avg linkage methods, due to the law of large numbers, the flipping noise is ``averaged out'' as soon as the set $E_{ij}$ becomes larger and clusters grow in size.
On the other hand, when clusters are small, it can happen that, for few clusters, several of their edges in $E_{ij}$ are flipped and the algorithm makes a mistake by merging two clusters belonging to different ground truth communities. From this observation, it follows that the \emph{flooding strategy} of the sum-linkage algorithm GAEC is a very good strategy on these types of graphs, because clusters are immediately grown in size (see dendrograms in Fig.~\ref{fig:dendrograms}). Average linkage method HC-Avg instead performs much worse on these graphs because it grows small equally-sized clusters and makes several wrong merge-decisions at the beginning. 
% This observation also explains the empirical results of \cite{chehreghani2020hierarchical}, which involved graph instances with very similar structure to the ones considered here. 
Lastly, the MWS algorithm is not expected to perform well on these graphs because of the high sensitivity of the AbsMax linkage to flipping noise. In the following Proposition \ref{prop:MWS_on_SSBM}, we prove that, at every iteration, the MWS algorithm makes a mistake with at least probability $\eta$, independently on the sizes of the two clusters that are popped from priority queue. In summary, for the SSBM, we can obtain a deep understanding of the dynamics induced by various linkage criteria, and find that GAEC gives highest accuracy by a large margin.
\begin{prop} \label{prop:MWS_on_SSBM}
Consider a graph generated by an Erd\H os-R\'enyi signed stochastic block model (SSBM) as described in Section \ref{sec:clustering_problems}, with $N$ nodes, edges added with probability $p$, sign-flip probability $\eta<0.5$, $k$ ground-truth clusters, and edge weights Gaussian-distributed with standard deviation $\sigma$. Then, at every iteration, \algname{} with Absolute Maximum linkage (or, in other words, the Mutex Watershed algorithm) always makes a mistake with at least probability $\eta$. 
\end{prop}
\begin{proof}
Thanks to Lemma \ref{lemma:absMax_and_complete_property} we know that \algname{} with Absolute Maximum linkage returns the same clustering whether or not cannot-link-constraints are used. Thus, in the following, we prove the proposition considering the version enforcing constraints.
Let us consider a generic iteration of the algorithm, where two clusters $S_\alpha$ and $S_\beta$ have the highest priority and are popped from priority queue. Then, the MWS algorithm will either merge or constrain them depending on the fact that their interaction $\interact_{\mathrm{AbsMax}}(S_\alpha,S_\beta)$ is  positive or negative (note that, with AbsMax linkage, an interaction can never be positive and constrained, as shown in Lemma \ref{lemma:absMax_and_complete_property}).
By construction of the SSBM, every edge $e\in E$ in the graph has a absolute weight distributed as $|w_e|\sim \mathcal{N}(1,\sigma^2)$. Thus, every edge $e'\in(S_{\alpha} \times S_{\beta})\cap E$ connecting the two clusters has the same probability to have the highest absolute weight, and the sign of the interaction $\interact_{\mathrm{AbsMax}}(S_\alpha,S_\beta)$ will only depend on the sign of this highest edge. Therefore, the probability that the MWS merges two clusters is simply given by the fraction of positive weighted edges connecting them.

Let $\tilde{\Pi}=\{\tilde{S}_1,\ldots,\tilde{S}_k\}$ denote the ground truth clustering, and $\tilde{S}_{\alpha i}=S_\alpha\cap \tilde{S}_i$ denote the intersection between cluster $S_{\alpha}$ and a ground-truth cluster $\tilde{S}_i$.
If the generated graph is dense, i.e. $p=1$, then the total number of edges connecting clusters $S_{\alpha}$ and $S_{\beta}$ that have a true attractive or repulsive weight is (according to the ground truth labels)
\begin{equation}
\NBE^+=\sum_{i=1}^k |\tilde{S}_{\alpha i}||\tilde{S}_{\beta i}|, \quad\quad\quad \NBE^-=\sum_{i=1}^k \sum_{j=1,j\neq i}^k |\tilde{S}_{\alpha i}||\tilde{S}_{\beta j}|.
\end{equation}
When the edges in the graph are randomly added with a probability $p$, then the actual number of true attractive and repulsive interactions connecting the two clusters is (according to the ground truth labels):
\begin{equation}
\nBE^+ \sim \mathcal{B}(\NBE^+,p), \qquad \nBE^- \sim \mathcal{B}(\NBE^-,p), 
\end{equation}
where $\mathcal{B}(\NBE,p)$ is the binomial distribution:
\begin{equation}
\mathcal{B}(\nBE;\NBE,p) = \frac{\NBE !}{\nBE! (\NBE-\nBE)!} p^\nBE (1-p)^{\NBE-\nBE}.
\end{equation}
Here, we only assume that $\nBE^+ + \nBE^- >0$, i.e. there is at least one edge connecting the two clusters (otherwise their interaction would be zero and the MWS would not have popped them from priority queue). 

So far we have been talking about attractive and repulsive connections according to the ground truth labels. In our SSBM however every edge has a uniform probability $\eta$ to have its sign flip, so  the actual number of attractive interactions connecting the two clusters will be instead given by the sum of the true attractive interactions $\nBE^+_{\mathrm{nf}}\sim \mathcal{B}(\nBE^+,1-\eta)$ that have not been flipped, plus the true negative interactions $\nBE^-_{\mathrm{f}}\sim \mathcal{B}(\nBE^-,\eta)$ that have been flipped.
Putting everything together, given two clusters with $\nBE^+$ true attractive interactions and $\nBE^-$ true negative ones, the highest-absolute-weight edge connecting them has the following probability to be positive:
\begin{align}\label{eq:mws_prob}
 \mathbb{P}[\interact_{\mathrm{AbsMax}}(S_\alpha,S_\beta)>0;\nBE^+,\nBE^-] = &\, \sum_{\nBE^+_{\mathrm{nf}}=0}^{\nBE^+}\sum_{\nBE^-_{\mathrm{f}}=0}^{\nBE^-} 
\mathcal{B}(\nBE^-_{\mathrm{f}};\nBE^-,\eta) \mathcal{B}(\nBE^+_{\mathrm{nf}};\nBE^+,1-\eta) \cdot \left(\frac{\nBE^+_{\mathrm{nf}}+\nBE^-_{\mathrm{f}}}{\nBE^+ + \nBE^-} \right) \nonumber\\
\stackrel{(*)}{=}&\,\frac{\nBE^+(1-\eta)+\nBE^-\eta}{\nBE^+ + \nBE^-}
\end{align}  
where in $(*)$ we used the fact that the expected value of a binomial distribution $\mathcal{B}(\nBE,\eta)$ is $\nBE \eta$.

%Now we note that this probability is always bounded in the interval $[\eta, 1-\eta]$ (or $[1-\eta, \eta]$, if $\eta>0.5$). Remarkably, these lower and upper bounds do not depend on the number of edges connecting the two clusters, i.e. $\nBE^+ + \nBE^-$ (and, thus, on the sizes of the two clusters). 
Now we note that this probability is bounded in the interval $[\eta, 1-\eta]$. So, regardless of whether the two clusters $S_\alpha$ and $S_\beta$ should be merged or constraint according to ground truth labels, the probability not to make the correct decision is always at least $\eta$.
% So weather we consider a merge or a split of the two clusters as the correct decision, in both cases the expected probability to not make that decision is at least $\eta$. Notably while the exact probabilities depend on the cluster sizes, the lower bound does not. This confirms the intuition that the MWS, unlike Sum or Avg linkage methods, cannot properly correct for sign flip noise by agglomerating larger boundaries and profiting from the law of large numbers. 
Remarkably, while the exact probability in Eq.~\ref{eq:mws_prob} depends on the number of edges connecting the two clusters $\nBE^++\nBE^-$ and thus on the cluster sizes, the bounds do not. Thus, this result shows that, unlike Sum or Avg linkage methods, the MWS algorithm is unable to reliably correct for the sign flip noise even for big clusters linked by many edges.
\end{proof}





\begin{table}[tp]
        \centering
\small
% \begin{minipage}[t]{0.6\textwidth}
%     \centering
        \begin{subtable}[t]{\textwidth}
        \centering
        \rowcolors{3}{gray!25}{white}
        \begin{tabular}[t]{l c c c c}
        \toprule
          & ARAND & VOI & VOI&  Runtime \\ 
          & Error & split & merge&  (s) \\ \midrule 
\textbf{HC-Avg} & \textbf{0.0487} & 0.387 & 0.258 & 2344 \\
HCC-Avg & 0.0492 & 0.389 & 0.259 & 2892 \\
MWS \cite{wolf2018mutex} & 0.0554 & 0.440 & 0.249 & 688 \\
GAEC \cite{keuper2015efficient} & 0.0856 & 0.356 & 0.338 & 4717 \\
HCC-Sum & 0.0872 & 0.365 & 0.337 & 4970 \\
% HCC-Complete & 0.9206 & 4.531 & \textbf{0.210} & 1330 \\
HC-Complete & 0.9211 & 4.536 & \textbf{0.211} & 1020 \\
HC-Single & 0.9264 & \textbf{0.060} & 4.887 & \textbf{312} \\
HCC-Single & 0.9264 & \textbf{0.060} & 4.887 & 6440 \\
        \end{tabular}
    % \captionof{table}{CREMI-Scores achieved by different linkage criteria and thresholding. All methods use the affinity predictions from our CNN as input. Scores are averaged over the three CREMI training datasets.}
    \caption{\centering CREMI-gridGraph (OurCNN)}
    \vspace*{2.5em}
    \label{tab:scores_gridGraph}
    \end{subtable}
\begin{subtable}[t]{\textwidth}
\centering
\rowcolors{3}{gray!25}{white} % \rowcolors{<starting row index>}{<dispari row color>}{<pari row color>}
        \begin{tabular}[t]{@{\hspace{0.7\tabcolsep}}l c @{\hspace{1\tabcolsep}} c @{\hspace{1.1\tabcolsep}} c @{\hspace{1\tabcolsep}} c @{\hspace{1\tabcolsep}}}
        \toprule
        % \rowcolor{gray!50}
          & ARAND & VOI & VOI&  Runtime \\ 
          % \rowcolor{gray!50}
          & Error & split & merge&  (s) \\ \midrule 
\textbf{HC-Avg} & \textbf{0.0896} & 0.603 & 0.323 & 86 \\
HCC-Avg & 0.0898 & 0.600 & 0.325 & 87 \\
GAEC \cite{keuper2015efficient} & 0.0905 & 0.606 & 0.323 & 89 \\
HCC-Sum & 0.0910 & 0.608 & 0.323 & \textbf{85} \\
MWS \cite{wolf2018mutex} & 0.1145 & 0.825 & 0.295 & 86 \\
HCC-Single & 0.5282 & \textbf{0.437} & 1.367 & 88 \\
HC-Single & 0.5282 & \textbf{0.437} & 1.367 & \textbf{85} \\
% HCC-Complete & 0.5564 & 2.220 & 0.254 & 89 \\
HC-Complete & 0.5654 & 2.253 & \textbf{0.249} & 86 \\
        \end{tabular}
        % \hspace*{5em}
    \caption{\centering CREMI-3D-RAG (OurCNN)}
    \vspace*{2.5em}
    \label{tab:scores_3drag}
    \end{subtable}

    \begin{subtable}[t]{\textwidth}
    % \end{table}
% \end{minipage}\hfill
% \begin{minipage}[t]{0.38\textwidth}
    \centering
    \rowcolors{3}{gray!25}{white} % \rowcolors{<starting row index>}{<dispari row color>}{<pari row color>}
        \begin{tabular}[t]{l @{\hspace{1.2\tabcolsep}} c @{\hspace{1\tabcolsep}} c @{\hspace{1\tabcolsep}} c @{\hspace{0.8\tabcolsep}} c @{\hspace{1\tabcolsep}} c}
        % \begin{tabular}[t]{lcccc}
        \toprule
        & Needs & CREMI& ARAND & VOI & VOI\\ 
          & superpixels? & Score & Error & split & merge\\ \midrule 
          % & \makecell{CREMI\\Score} & \makecell{ARAND\\error} & \makecell{VOI\\split} & \makecell{VOI\\merge}    \\ \midrule 
OurCNN: 3D-RAG + LiftedMulticut & \CrossedBox & \textbf{0.221} & \textbf{0.108} & \textbf{0.339} & 0.115 \\
\emph{GASP: OurCNN + gridGraph + HCC-Avg} & \HollowBox & 0.224 & 0.113 & 0.361 & 0.085  \\
\emph{GASP: OurCNN + gridGraph + HC-Avg}  & \HollowBox &0.224 & 0.114 &  0.364 & 0.083 \\
PNI CNN \cite{lee2017superhuman} & \CrossedBox &0.228 & 0.116 & 0.345 & 0.106 \\
LSI-Masks \cite{bailoni2020proposal}  & \HollowBox &0.246 & 0.125 & 0.383 & 0.107  \\
\emph{GASP: OurCNN + 3D-RAG + HCC-Avg} & \CrossedBox &0.257 & 0.132 & 0.438& \textbf{0.063} \\  
\emph{GASP: OurCNN + 3D-RAG + HC-Avg} & \CrossedBox &0.262 & 0.135 & 0.448 & \textbf{0.063}   \\  
% \textbf{Our CNN + \algname{} Average} & \textbf{0.241 \\
MALA CNN + MC \cite{funke2018large} & \CrossedBox & 0.276  & 0.132 &0.490  & 0.089  \\
CRU-Net \cite{zeng2017deepem3d} & \CrossedBox &0.566 & 0.229 & 1.081 &  0.389    \\
% LFC \cite{parag2017anisotropic} & 0.616 & 0.313 & 1.085 & 0.140     \\
        \end{tabular}
        \caption{\centering CREMI Challenge leader-board}
        \vspace*{1.5em}
        \label{tab:cremi_leaderboard}
        \end{subtable}
        % \vspace*{0.99em}
    % \captionof{table}{Current leading entries  in the CREMI challenge leaderboard \cite{cremiChallenge} (March 2021)}
    % \label{tab:results_cremi_test}
    \caption{\textbf{(a-b)}: Scores and run times of algorithms in the \algname{} framework on the \emph{CREMI-gridGraph} and \emph{CREMI-3D-RAG} clustering problems: average linkage methods achieved the best accuracy. Measures shown are: Adapted-Rand error (ARAND, lower is better); Variation of Information (VOI) \cite{arganda2015crowdsourcing} (VOI-merge for under-clustering error and VOI-split for over-clustering error, lower values are better). \textbf{(c)}: Current leading entries in the CREMI challenge leaderboard. CREMI-score is given by the geometric mean of (VOI-split + VOI-merge)  and ARAND error (lower is better).}
    \label{tab:scores}
% \end{minipage}
\end{table}
\begin{figure}[tp]
\centering
\includegraphics[width=\textwidth,trim=0 10 60 0, clip]{./figures/GASP/comparison_GAEC_MWS_Avg.png} % left bottom right top
\caption{Failure cases of three versions of \algname{} applied to neuron segmentation. Only \emph{wrongly} segmented regions are highlighted in different warm colors. Red arrows point to wrongly split regions; yellow arrows point to false merge errors. HC-Avg returned the best segmentation. Data is 3D, hence the same color could be assigned to parts of segments that appear disconnected in 2D.  
\label{fig:failure_cases}}
\end{figure}
\begin{figure}[tbp]
\centering
\includegraphics[width=0.87\textwidth,trim=0.2in 0.17in 0.2in 0.2in,clip]{./figures/GASP/noise_plots_adapted-rand_1.pdf}
        \caption{
ARAND errors (median values over 20 experiments, lower is better) on \emph{CREMI-gridGraph} clustering problems perturbed with structured noise. Average-linkage algorithms proved to be the most robust.
% We report median, 25th, and the 75th percentile values over \TODO{30} experiments.
% \algname{} performances compared to spectral methods on synthetic graphs. The spectral methods were given the true number of clusters as input, in contrast to \algname{}. \TODO{Define paramters SSB; explain percentile stuff (for both noise experiments), user ARAND-error}
}\label{fig:scores_structured_noise}
\end{figure}


\subsubsection{GASP on neuron segmentation graph instances}
SSBM graphs are \emph{non-planar}, and every edge has the same probability to be present in the graph. On the other hand, the \emph{gridGraph} and \emph{3D-RAG} graphs of Table~\ref{tab:datasets} are sparse and have a very regular structure: regardless of whether a node represents a pixel or a superpixel, it will only have edge connections with its neighbors in the image (up to a certain hop distance). 
Tables~\ref{tab:scores_gridGraph}-\ref{tab:scores_3drag} show that average linkage methods (HC-Avg, HCC-Avg) strongly outperform other methods on \emph{CREMI-gridGraph} instances and also achieve the best scores on \emph{CREMI-3D-rag} graphs. Sum-based linkage methods (GAEC, HCC-Sum) have a two times higher ARAND error on grid-graphs and often return under-clustered segments (see failure cases in Fig.~\ref{fig:failure_cases}). This suggests that the \emph{flooding strategy} observed previously in the sum-linkage methods does not work on grid-graphs, because in this setup edge weights are predicted by a CNN and noise is strongly spatially-correlated \footnote{This effect is not as strong on \emph{3D-RAG} graphs, because edge weights are computed by averaging CNN predictions (and noise) over the boundaries of adjacent supervoxels.}.
To fully test this hypothesis, we conduct a set of experiments where the CNN predictions are perturbed by adding structured noise and simulating additional artifacts like ``holes'' in the boundary evidence\footnote{See Appendix \ref{sec:appendix_noise_gen} for details about how we perturbed the \emph{CREMI-gridGraph} problems by using Perlin noise \cite{perlin2001noise,perlin1985image}, which is one of the most common gradient noises used in procedural pattern generation.}. 
The plot in Fig.~\ref{fig:scores_structured_noise} confirms that HC-Avg and HCC-Avg are very robust algorithms on this data, followed by Sum-linkage algorithms and the Mutex Watershed algorithm (MWS). It is not a surprise that the AbsMax linkage used by MWS is not robust to this type of structured noise. However, the scores and runtimes in Table~\ref{tab:scores_gridGraph} prove how MWS can achieve high accuracy with 70\% lower runtime compared to HC-Avg. 

\paragraph{Complete and Single Linkage} We use these two linkage methods as baselines to highlight the difficulty of the studied graph clustering problems listed in Table~\ref{tab:datasets}. Scores in Tables~\ref{tab:scores_gridGraph}-\ref{tab:scores_3drag} show their poor performance: Single linkage hierarchical clustering (HC-Single), which here is equivalent to thresholding the edge weights at $w_e=0$ and computing connected components in the graph, often returned few big under-segmented clusters. HC-Complete returned instead a lot of over-segmented clusters. 
% These algorithms are excluded from our next comparison experiments.








\paragraph{Results on CREMI challenge} 
Table~\ref{tab:cremi_leaderboard} shows that the HCC-Avg and HC-Avg clustering algorithms achieve state-of-the-art accuracy on the CREMI challenge, when combined with predictions of our CNN.
Most of the other entries (apart from \emph{LSI-Masks} \cite{bailoni2020proposal}) employ super-pixels based post-processing pipelines and cluster 3D-region-adjacency graphs. As we show in Table ~\ref{tab:scores_3drag}, using superpixels considerably reduces the size of the clustering problem and, consequently, the post-processing time. 
However, our method operating directly on pixels (\emph{gridGraph + HCC-Avg}) achieves better performances than superpixel-based methods (\emph{3D-RAG + HCC-Avg}) and does not require the parameter tuning necessary to obtain good super-pixels, which is usually highly dataset dependent.
To scale up our method operating on pixels, we divided each test-volume into four sub-blocks, and then combined the resulting clusterings by running the algorithms again on the combined graph.
The method \emph{3D-RAG + LiftedMulticut} based on the lifted multicut approximation of \cite{beier2017multicut} achieves the best scores overall, but it takes into account different information through the lifted edge weights that also depend on additional raw-data and shape information from highly engineered super-pixels. 
% Note that the test volumes of the challenge contain several imaging artifacts that make segmentation particularly challenging.
% However: handcrafted and dataset dependent, performs better, no

% Given By building a grid-graph from our CNN predictions  and solving a clustering problem with the \emph{HCC-Avg} and \emph{HC-Avg} algorithms, representing the best performing algorithms included in the proposed \algname{} framework, we achieve state-of-the-art performances on the competitive CREMI challenge (see Table~\ref{tab:cremi_leaderboard}). 

% To scale up the pixel-based aggSpecify that we divided samples into four blocks and then run the agglomeration again (moreover, run seeded WS to get rid of small segments).

% then \algname{} with cannot-link constraints shows a clear tendency to over-cluster. \\

% Superpixels are nice because they reduce runtime and represents the standard choices for connectomics (all bug LSI-Masks use some kind of similar form). But method is very dataset-dependent and require the user to set a series of parameters

% So far no other method was done from pixels







% The competitive performance of this simple parameter-free algorithm is also reported in Table \ref{tab:results_cremi_test}, showing the current leader-board of the challenge: 


% Note that the test volumes contain several imaging artifacts that make segmentation particularly challenging. 
% and might profit from more robust edge statistics of super-pixel based approaches.

% and can also avoid errors that result from wrong superpixels that cannot be fixed during later agglomeration.
% In Appendix \ref{sec:appendix_exps_full_cremi}, we provide more details about how we scaled up \algname{} to the full datasets. 
% Appendix Table \ref{tab:extended_results_cremi} lists the performances and the run-times for all tested \algname{} linkage criteria.\\


% We first evaluate and compare the agglomerative clustering algorithms described in the generalized framework on the task of neuron segmentation in electron microscopy (EM) image volumes. This application is of key interest in connectomics, a field of neuro-science with the goal of reconstructing neural wiring diagrams spanning complete central nervous systems. Currently, only proof-reading or manual tracing yields sufficient accuracy for correct circuit reconstruction \cite{schlegel2017learning}, thus further progress is required in automated reconstruction methods.

% EM segmentation is commonly performed by first predicting 
% boundary pixels \cite{beier2017multicut,ciresan2012deep} or undirected affinities \cite{wolf2018mutex,lee2017superhuman,funke2018large}, which represent how likely it is for a pair of pixels to belong to the same neuron segment. 
% The affinities do not have to be limited to immediately adjacent pixels.
% Thus, similarly to \cite{lee2017superhuman}, we train a CNN to predict both short- and long-range affinities
% and use them as edge weights of a 3D grid graph, where each node represents a pixel/voxel of the volume image. 


